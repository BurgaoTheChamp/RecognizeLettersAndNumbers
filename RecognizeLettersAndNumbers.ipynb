{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cluster\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and testing an image via Pillow Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG\n",
      "(1360, 768)\n",
      "RGB\n"
     ]
    }
   ],
   "source": [
    "#A variable is assigned to open and hold the test image\n",
    "imageTest = Image.open(\"imageTest.jpg\");\n",
    "\n",
    "#some details checking about the image\n",
    "print(imageTest.format);\n",
    "print(imageTest.size);\n",
    "print(imageTest.mode);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the image loaded into an Array from NumPy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(768, 1360, 3)\n",
      "[[[ 75   2  73]\n",
      "  [ 75   2  73]\n",
      "  [ 75   2  73]\n",
      "  ...\n",
      "  [ 76   3  72]\n",
      "  [ 75   2  71]\n",
      "  [ 75   2  71]]\n",
      "\n",
      " [[ 75   2  73]\n",
      "  [ 75   2  73]\n",
      "  [ 75   2  73]\n",
      "  ...\n",
      "  [ 74   1  70]\n",
      "  [ 74   1  70]\n",
      "  [ 73   0  69]]\n",
      "\n",
      " [[ 75   2  73]\n",
      "  [ 75   2  73]\n",
      "  [ 75   2  73]\n",
      "  ...\n",
      "  [ 75   2  71]\n",
      "  [ 75   2  71]\n",
      "  [ 75   2  71]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  1  75 234]\n",
      "  [  1  75 234]\n",
      "  [  0  75 229]\n",
      "  ...\n",
      "  [ 62  48 145]\n",
      "  [ 62  48 143]\n",
      "  [ 61  47 144]]\n",
      "\n",
      " [[ 36  49 179]\n",
      "  [ 36  49 177]\n",
      "  [ 36  50 173]\n",
      "  ...\n",
      "  [ 68  62 152]\n",
      "  [ 68  61 154]\n",
      "  [ 67  61 151]]\n",
      "\n",
      " [[ 55  65 215]\n",
      "  [ 54  66 214]\n",
      "  [ 54  66 214]\n",
      "  ...\n",
      "  [ 30 140 255]\n",
      "  [ 30 142 254]\n",
      "  [ 29 139 252]]]\n",
      "<class 'PIL.Image.Image'>\n",
      "RGB\n",
      "(1360, 768)\n",
      "[[ 32  32  32 ...  33  32  32]\n",
      " [ 32  32  32 ...  31  31  30]\n",
      " [ 32  32  32 ...  32  32  32]\n",
      " ...\n",
      " [ 71  71  70 ...  63  63  62]\n",
      " [ 60  60  60 ...  74  74  73]\n",
      " [ 79  79  79 ... 120 121 119]]\n"
     ]
    }
   ],
   "source": [
    "#using np.array() to convert an image in numpy array\n",
    "imageArray = np.array(imageTest);\n",
    "\n",
    "#printing the typr of it\n",
    "print(type(imageArray));\n",
    "\n",
    "#printing the shape of the image\n",
    "print(imageArray.shape);\n",
    "\n",
    "#priting the data of the imageArray representing each pixel of it\n",
    "print(imageArray);\n",
    "\n",
    "#Creating an image from the imageArray\n",
    "imageCreated = Image.fromarray(imageArray);\n",
    "print(type(imageCreated));\n",
    "\n",
    "#Check the image details\n",
    "print(imageCreated.mode);\n",
    "print(imageCreated.size);\n",
    "\n",
    "#converting the image to greyscale\n",
    "imageGreyscale = imageTest.convert(\"L\");\n",
    "\n",
    "#saving the image\n",
    "imageGreyscale.save(\"greyscale.jpeg\");\n",
    "\n",
    "#Priting the data of the imageGreyscale\n",
    "print(np.array(imageGreyscale));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to load image and convert to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 32  32  32 ...  33  32  32]\n",
      " [ 32  32  32 ...  31  31  30]\n",
      " [ 32  32  32 ...  32  32  32]\n",
      " ...\n",
      " [ 71  71  70 ...  63  63  62]\n",
      " [ 60  60  60 ...  74  74  73]\n",
      " [ 79  79  79 ... 120 121 119]]\n"
     ]
    }
   ],
   "source": [
    "def imageLoadGrey(image):\n",
    "    \"Converts an image to greyscale and return an array about it\"\n",
    "    return np.array(image.convert(\"L\"));\n",
    "\n",
    "#testing the function\n",
    "print(imageLoadGrey(imageTest));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset utilized is Balanced dataset within the Extended MNIST\n",
    "\n",
    "1. The EMNIST Balanced dataset is meant to address the balance issues in the ByClass and ByMerge datasets. It is derived from the ByMerge dataset to reduce     mis-classification errors due to capital and lower case letters and also has an equal number of samples per class. This dataset is meant to be the most applicable.\n",
    "    train: 112,800\n",
    "    test: 18,800\n",
    "    total: 131,600\n",
    "    classes: 47 (balanced)\n",
    "\n",
    "2. CSV  (combined labels and images)\n",
    "    The datasets are called \"emnist-balanced-test\" and \"emnist-balanced-train\" every element is separated by comma and there are no empty elements\n",
    "    Each row is a separate image.\n",
    "    The dataset has 785 colums and the First column is the class label (see mappings.txt for class label definitions).\n",
    "    Each column after the class label, represents one pixel value (784 total for a 28 x 28 image).\n",
    "    Each pixes has and associated value raging from 0 to 255(inclusive), indicating its greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readinf the dataset test and train and showing it's first 5 rows\n",
    "dataSetTest = pd.read_csv(\"archive\\emnist-balanced-test.csv\", sep=\",\");\n",
    "dataSetTrain = pd.read_csv(\"archive\\emnist-balanced-train.csv\", sep=\",\");\n",
    "dataSetTest.head(5);\n",
    "dataSetTrain.head(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d2bf5af61742e4ead77ddd8b0bfd3e299d621004bd2b5f4571431621f902a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
